{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "\n",
    "This homework will explore linear regression and resampling techniques by analyzing data from a database of glaciers. The database is *Glatilda* for [*Glacier Ice Thickness Database*](!https://www.gtn-g.ch/data_catalogue_glathida/).\n",
    "\n",
    "1. Data prep (5 points)\n",
    "2. Mapping (10 points)\n",
    "3. Correlations between parameters (5 points)\n",
    "4. Linear regression and resampling techniques (10 points)\n",
    "\n",
    "## 1. Data Prep (5 points total)\n",
    "\n",
    "### a) Download data (1 point) \n",
    "The database is saved on a GitLab repository that you may clone: https://gitlab.com/wgms/glathida.git\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests, zipfile, io, gzip, glob, os\n",
    "import requests, zipfile, io, gzip, glob, os\n",
    "import pandas as pd\n",
    "\n",
    "glaci = pd.read_csv(\"glacier.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Import Python modules (1 point) \n",
    "Import pandas, geopandas, plotting, raster files,  numpy, netcdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio as ra\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import netCDF4 as nc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Read data (2 points)\n",
    "Read the glacier data from the file ``glathida/data/glacier.csv`` into a pandas data frame, and decribe briefly the dataframe content and its first few lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "t_path = \"glathida/data/glacier.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore the data with visualization**\n",
    "Before making any inference of models with the data, we will start by exploring basic correlations among parameters by plotting. In particular, we will focus on ``mean_thickness``, ``area``, ``mean_slope`` parameters.\n",
    "\n",
    "### d) Remove bad data (1 point)\n",
    "\n",
    "The database may contain Nans and other \"bad\" values (welcome to the data world!). First we will clean the data by removing nans. We are mostly interested in the thickness, area, and slope\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  survey_id                   name external_db   external_id  \\\n",
      "0        1          1       Isfallsglaciären         WGI  SE4B000E0006   \n",
      "1        2          1         Rabots glaciär         WGI  SE4B000E1016   \n",
      "2        3          1          Storglaciären         WGI  SE4B000E0005   \n",
      "3        4          2  South Cascade Glacier         WGI  US2M00264006   \n",
      "4        5          3      Athabasca Glacier         FOG             7   \n",
      "...    ...        ...                    ...         ...           ...   \n",
      "1008  6627        254            Mount Adams         NaN           NaN   \n",
      "1009  6628        255            Mount Adams         NaN           NaN   \n",
      "1010  6629        256            Mount Adams         NaN           NaN   \n",
      "1011  6630        128           Mullwitzkees         AGI          6054   \n",
      "1012  6631        128           Mullwitzkees         AGI          6054   \n",
      "\n",
      "           lat        lon        date    max_date    area  ...  \\\n",
      "0     67.91500   18.56800  1979-03-01  1979-03-31   1.300  ...   \n",
      "1     67.91000   18.49600  1979-03-01  1979-03-31   4.100  ...   \n",
      "2     67.90000   18.57000  1979-03-01  1979-03-31   3.100  ...   \n",
      "3     48.35698 -121.05735  1975-01-01  1975-12-31   2.000  ...   \n",
      "4     52.17540 -117.28400         NaN         NaN   3.800  ...   \n",
      "...        ...        ...         ...         ...     ...  ...   \n",
      "1008  46.20240 -121.49090  1935-01-01  1935-12-31     NaN  ...   \n",
      "1009  46.20240 -121.49090  2002-05-01  2002-05-31  16.200  ...   \n",
      "1010  46.20398 -121.49376  2006-07-01  2006-07-31     NaN  ...   \n",
      "1011  47.08670   12.38000  1998-01-01  1998-12-31   3.229  ...   \n",
      "1012  47.08670   12.38000  2003-01-01  2003-12-31     NaN  ...   \n",
      "\n",
      "      mean_thickness  mean_thickness_uncertainty  max_thickness  \\\n",
      "0               72.0                         NaN          220.0   \n",
      "1               84.0                         NaN          175.0   \n",
      "2               99.0                         NaN          250.0   \n",
      "3               99.0                         NaN          195.0   \n",
      "4              150.0                         NaN            NaN   \n",
      "...              ...                         ...            ...   \n",
      "1008             NaN                         NaN            NaN   \n",
      "1009            57.0                         NaN            NaN   \n",
      "1010             NaN                         NaN          120.0   \n",
      "1011            39.0                         9.0           78.0   \n",
      "1012             NaN                         NaN            NaN   \n",
      "\n",
      "      max_thickness_uncertainty  number_points  number_profiles  \\\n",
      "0                           NaN            NaN              NaN   \n",
      "1                           NaN            NaN             10.0   \n",
      "2                           NaN            NaN              NaN   \n",
      "3                           NaN            NaN              NaN   \n",
      "4                           NaN            NaN              NaN   \n",
      "...                         ...            ...              ...   \n",
      "1008                        NaN           14.0              NaN   \n",
      "1009                        NaN          217.0              NaN   \n",
      "1010                        NaN           78.0              NaN   \n",
      "1011                       13.0           30.0              NaN   \n",
      "1012                        NaN            1.0              NaN   \n",
      "\n",
      "      length_profiles  interpolation_method     flag  \\\n",
      "0                 NaN                   NaN      NaN   \n",
      "1                 NaN                   NaN      NaN   \n",
      "2                 NaN                   NaN      NaN   \n",
      "3                 NaN                   NaN      NaN   \n",
      "4                 NaN                   NaN      NaN   \n",
      "...               ...                   ...      ...   \n",
      "1008              NaN                   NaN      NaN   \n",
      "1009              NaN                   NaN      NaN   \n",
      "1010              NaN                   NaN  partial   \n",
      "1011              NaN                anudem      NaN   \n",
      "1012              NaN                   NaN      NaN   \n",
      "\n",
      "                                                remarks  \n",
      "0                                                   NaN  \n",
      "1                                                   NaN  \n",
      "2                                                   NaN  \n",
      "3                                                   NaN  \n",
      "4                                                   NaN  \n",
      "...                                                 ...  \n",
      "1008                                                NaN  \n",
      "1009  AREA: Sitts et al. 2010 (https://doi.org/10.39...  \n",
      "1010                                                NaN  \n",
      "1011  LAT/LON: FoG 2015 | AREA: Austrian Glacier inv...  \n",
      "1012  LAT/LON: FoG 2015 | AREA: Austrian Glacier inv...  \n",
      "\n",
      "[1013 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "glaci.shape\n",
    "print(glaci)\n",
    "\n",
    "#glaci.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mapping glaciers (10 points)\n",
    "\n",
    "Make a global map of the glaciers. Use either of the tools we learned in class:\n",
    "* Geopandas, DEMs from NetCDFfiles (see chapter 2.4)\n",
    "* Pandas and Plotly (see chapter 2.2). You may need to transform some of the series into log-spaced values for better visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Tif and matplotlib\n",
    "\n",
    "You can use the ``elevation`` data from the DEM seen in class. Download the DEM file (https://www.dropbox.com/s/j5lxhd8uxrtsxko/HYP_50M_SR.tif?dl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "___Tips___: when plotting a image in ``matplotlib`` you need to add information about the physical dimensions of the image. You can calculate the ``bounds``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = (elevation.bounds.left, elevation.bounds.right, \\\n",
    "          elevation.bounds.bottom, elevation.bounds.top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use ``matplotlib.pyplot`` to show the raster image in the background (tips: use ``imshow()``. The raster image in matplotlib can only import one frame and not three (R, G, B) frames. We will first stack the three images together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = elevation.read(1)\n",
    "green = elevation.read(2)\n",
    "blue = elevation.read(3)\n",
    "pix = np.dstack((red, green, blue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 2: Plotly\n",
    "\n",
    "You may use plotly. For improved visibility, transform some of the data into log-spaced. You may add these transformed Series into the Pandas, and use them as input to plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'vscode' # writes as standalone html, \n",
    "# pio.renderers.default = 'iframe' # writes files as standalone html, \n",
    "# pio.renderers.default = 'png' # writes files as standalone html, \n",
    "# try notebook, jupyterlab, png, vscode, iframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Correlations between data parameters ( 5 points total)\n",
    "\n",
    "Make plots to vizualise the correlation, or lack of, between all three data. Make at least three plots.\n",
    "\n",
    "### a) Basic correlations using Matplotlib (2 points)\n",
    "\n",
    "Make 3 plots using matplotlib to visualize slope, mean_thickness, and area. Use logscale to see the correlatons.\n",
    "\n",
    "__Tips__: \n",
    "* Use the function ``scatter`` to plot the values of mean thickness, mean slope, area, and latitude. \n",
    "* use one of the dataframe columns as a color using the argument ``c``. You can also vary the ``colormap`` using the argument ``cmap``. Help on colormaps can be found here: https://matplotlib.org/stable/tutorials/colors/colormaps.html. Be mindful of Color-Vision Deficient readers and read *Crameri, F., Shephard, G.E. and Heron, P.J., 2020. The misuse of colour in science communication. Nature communications, 11(1), pp.1-10. https://doi.org/10.1038/s41467-020-19160-7* (find it on the class Gdrive). You can add a third \"data\" by choosing a marker color that scales with an other parameter. For instance, try coloring your marker with the ``LAT`` parameter to look at systematic latitudinal trends from the equator to the poles.\n",
    "* Do not forget to adjust fontsize, figure size (at least 10,8), grid, labels with units. ou may also explore the *logarithmic* correlations by mapping the axis from linear to logarithmic scale ``plt.xscale('log')``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: Mean slope vs mean thickness\n",
    "# solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: area vs mean thickness\n",
    "# solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) 3D Scatter plot using Plotly (1 point)\n",
    "\n",
    "Use the plotly ``scatter_3d`` plot. Make sure to change the pandas series for log scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Pandas Correlation function (1 point)\n",
    "\n",
    "You may use Pandas functionalities to explore correlation between data. Use the function ``corr`` on the dataframe and the matplotlib function ``matshow`` to plot a heatmap of the correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f) Seaborn Plotting (1 point)\n",
    "\n",
    "Seaborn is a great python package for basic data anlytics. See documentation [here](!https://seaborn.pydata.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss the basic correlations among the data. Do these correction make sense when you think about the shapes of glaciers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enter text below\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Linear Regression (10 points total counted in the next section)\n",
    "You found from basic data visualization that the three parameters ``mean_slope``, ``mean_thickness``, and ``area`` are correlated. It does make physical sense because a *steep* glaciers is likely to be in the high mountains regions, hanging on the mountain walls, and thus be constrained, and conversely, a flat glacier is either at its valley, ocean terminus or on ice sheets.\n",
    "\n",
    "### a) Simple linear regression (2 points)\n",
    "We will now perform a regression between the parameters (or their log!). Linear regressions are models that can be imported from scikit-learn. Log/exp functions in numpy as ``np.log()`` and ``np.exp()``.\n",
    "Remember that a linear regression is finding $a$ and $b$ knowing both $x$ and the data $y$ in $y = Ax +b$. We want to predict ice thickness from a crude estimate of the glacier area.\n",
    "\n",
    "__Tips__: \n",
    "a. make sure that the dimensions are correct and that there is no NaNs and zeros.\n",
    "b. Make sure to inport the scikit learn linear regression function and the error metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a plot of the data and the linear regression your performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Briefly comment on the quality of your fit and a linear regression (1 point)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit looks pretty good, except that there are outliers on the extreme low and high values of mean area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Leave One Out Cross Validation linear regression (1 point)\n",
    "\n",
    "\n",
    "Perform the LOCCV on the ``area`` and ``thickness`` values. Predict the ``thickness`` value knowing a ``area`` value. Use material seen in class. Make a plot of your fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "# solution\n",
    "loo = LeaveOneOut()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Bootstrapping (1 point)\n",
    "\n",
    "Perform the same analysis but using a bootstrapping technique. Output the mean and standard deviation of the slope. An illustration with a histogram  may help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "# solution\n",
    "\n",
    "k=100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Predict the thickness of a glacier (2 points)\n",
    "\n",
    "Let assume that you measure a glacier of area 10 km$^2$. Can you use your bootstrap regression framework to provide a distribution of possible values of the ice thickness ? Output the mean and standard deviation of the predicted ice thickness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "k=100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a6825af05e3ea1f79f5651bdd3095330bdaee3a1e3958825bcb0ebbb42c21bf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
